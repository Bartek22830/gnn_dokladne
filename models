# Klasa definiująca model Graph Convolutional Network (GCN)
class GCN(torch.nn.Module):
    # Konstruktor klasy GCN przyjmuje rozmiar wejściowy, rozmiar warstwy ukrytej i rozmiar wyjściowy
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCN, self).__init__()
        # Inicjalizacja pierwszej warstwy konwolucyjnej GCN z wymiaru wejściowego na ukryty
        self.conv1 = GCNConv(input_dim, hidden_dim)
        # Inicjalizacja drugiej warstwy konwolucyjnej GCN z wymiaru ukrytego na wyjściowy
        self.conv2 = GCNConv(hidden_dim, output_dim)

    # Funkcja forward przeprowadza przepływ danych przez model
    def forward(self, data):
        # Sprawdzenie, czy dane są krotką (tuple) - zakładamy, że zawiera x i edge_index
        if isinstance(data, tuple):
            x, edge_index = data  # x - cechy węzłów, edge_index - indeksy krawędzi
        else:
            # Jeśli dane to obiekt (np. PyG Data), sprawdzamy, czy zawiera wymagane atrybuty x i edge_index
            if hasattr(data, 'x') and hasattr(data, 'edge_index'):
                x = data.x
                edge_index = data.edge_index
            else:
                # Wywołanie wyjątku, jeśli brakuje wymaganych atrybutów
                raise ValueError("Dane wejściowe nie zawierają odpowiednich kluczy ('x', 'edge_index').")

        # Sprawdzamy, czy x i edge_index to tensory, aby upewnić się, że nie są np. stringami
        if isinstance(x, torch.Tensor) and isinstance(edge_index, torch.Tensor):
            print(f"Przetwarzanie batcha: x = {x.shape}, edge_index = {edge_index.shape}")
        else:
            # Wywołanie wyjątku, jeśli x lub edge_index nie są tensorami
            raise ValueError("Wartość 'x' lub 'edge_index' jest ciągiem znaków, a nie tensorem!")

        # Przepływ danych przez pierwszą warstwę GCN z funkcją aktywacji ReLU
        x = F.relu(self.conv1(x, edge_index))
        # Przepływ przez drugą warstwę GCN bez aktywacji, jako że log_softmax jest wywoływany później
        x = self.conv2(x, edge_index)

        # Zwracamy wynik, przetworzony przez funkcję log_softmax dla klasyfikacji wieloklasowej
        return F.log_softmax(x, dim=1)


# Klasa definiująca model GraphSAGE
class GraphSAGE(torch.nn.Module):
    # Konstruktor klasy GraphSAGE przyjmuje rozmiar wejściowy, rozmiar warstwy ukrytej i rozmiar wyjściowy
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GraphSAGE, self).__init__()
        # Inicjalizacja pierwszej warstwy konwolucyjnej GraphSAGE (z wejściowego na ukryty)
        self.conv1 = SAGEConv(input_dim, hidden_dim)
        # Inicjalizacja drugiej warstwy konwolucyjnej GraphSAGE (z ukrytego na wyjściowy)
        self.conv2 = SAGEConv(hidden_dim, output_dim)

    # Funkcja forward definiująca przepływ danych przez model
    def forward(self, data):
        # Jeśli dane są w formacie PyG (z atrybutami x i edge_index), przypisujemy je odpowiednio
        if hasattr(data, 'x') and hasattr(data, 'edge_index'):  # PyG
            x, edge_index = data.x, data.edge_index
        else:  # DGL
            # Jeśli graf jest heterogeniczny (zawiera różne typy węzłów)
            if isinstance(data.ndata['feat'], dict):
                # Pobieramy cechy węzłów dla typu '_N' (ogólnie głównego typu węzła)
                x = data.ndata['feat']['_N']
                # Pobieramy pary krawędzi (krawędzie grafu) jako edge_index
                edge_index = torch.stack(data.edges(), dim=0)
            else:
                # W przypadku grafu jednorodnego pobieramy cechy węzłów bezpośrednio
                x = data.ndata['feat']
                edge_index = torch.stack(data.edges(), dim=0)

        # Przepływ danych przez pierwszą warstwę GraphSAGE z aktywacją ReLU
        x = F.relu(self.conv1(x, edge_index))
        # Przepływ przez drugą warstwę GraphSAGE bez aktywacji
        x = self.conv2(x, edge_index)
        # Wynik log_softmax dla klasyfikacji wieloklasowej
        return F.log_softmax(x, dim=1)


# Klasa definiująca model Graph Attention Network (GAT)
class GAT(torch.nn.Module):
    # Konstruktor klasy GAT przyjmuje rozmiar wejściowy, rozmiar warstwy ukrytej, rozmiar wyjściowy oraz liczbę głów (heads)
    def __init__(self, input_dim, hidden_dim, output_dim, heads=1):
        super(GAT, self).__init__()
        # Inicjalizacja pierwszej warstwy konwolucyjnej GAT z liczbą głów (heads)
        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)
        # Inicjalizacja drugiej warstwy konwolucyjnej GAT, przy czym rozmiar wejściowy jest dostosowany do liczby głów
        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1)

    # Funkcja forward, definiująca przepływ danych przez model GAT
    def forward(self, data):
        # Jeśli dane są w formacie PyG, przypisujemy je do zmiennych x i edge_index
        if hasattr(data, 'x') and hasattr(data, 'edge_index'):  # PyG
            x, edge_index = data.x, data.edge_index
        else:  # DGL
            # Jeśli graf jest heterogeniczny, pobieramy dane dla głównego typu węzła '_N'
            if isinstance(data.ndata['feat'], dict):
                x = data.ndata['feat']['_N']
            else:
                # W przeciwnym razie, dla grafu jednorodnego pobieramy cechy węzłów bezpośrednio
                x = data.ndata['feat']

            # Pobieramy krawędzie grafu i tworzymy edge_index przez ich złączenie
            edge_index = torch.stack(data.edges(), dim=0)

        # Przepływ danych przez pierwszą warstwę konwolucyjną GAT z aktywacją ReLU
        x = F.relu(self.conv1(x, edge_index))  # Pierwsza warstwa GATConv
        # Przepływ przez drugą warstwę konwolucyjną GAT
        x = self.conv2(x, edge_index)          # Druga warstwa GATConv

        # Zwracamy wynik przetworzony przez log_softmax dla klasyfikacji wieloklasowej
        return F.log_softmax(x, dim=1)
